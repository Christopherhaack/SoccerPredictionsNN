{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeStepX(x):\n",
    "    xRet = []\n",
    "    for xt in x:\n",
    "        xTemp = []\n",
    "        for i in range(5):\n",
    "            h = xt[i * 824: (i +1) * 824]\n",
    "            a = xt[(i+5) * 824: (i + 6) * 824]\n",
    "            val = h + a\n",
    "            xTemp.append(val)\n",
    "        xRet.append(xTemp)\n",
    "    return xRet\n",
    "def resVal(y):\n",
    "    yVals = []\n",
    "    for val in y:\n",
    "        if val[0] == 1:\n",
    "            yVals.append(3)\n",
    "        elif val[1] == 1:\n",
    "            yVals.append(1)\n",
    "        else:\n",
    "            yVals.append(0)\n",
    "    return yVals\n",
    "\n",
    "#changes the output of a game to a one hot encoding [win, tie, loss]\n",
    "def resOneHot(y):\n",
    "    if y == 3:\n",
    "        return [1 , 0, 0]\n",
    "    elif y == 1:\n",
    "        return [0, 1, 0]\n",
    "    else:\n",
    "        return [0, 0, 1]\n",
    "\n",
    "#creates a flat version of the x as a 1 x 8240 matrix and the y's as one hot vectors.\n",
    "def createDataSet2(gameInfo, season):\n",
    "    \n",
    "    ''' code used to create x and y values from a given season and set of games\n",
    "    creates a y value that is listed as a one hot vector\n",
    "     and x as a 1 x 8240 matrix that give information about the past 5 games'''\n",
    "    x = []\n",
    "    y = []\n",
    "    cnt = 0\n",
    "    teamDic = dict()\n",
    "    teams = season.teams\n",
    "    #this code block is meant to fix a mistake in the definition of my data structure, should really make performances\n",
    "    # a dictionary which each team name as a key, and the performances as a val. \n",
    "    for team in teams:\n",
    "        teamDic[team] = cnt\n",
    "        cnt += 1\n",
    "    for game in gameInfo:\n",
    "        example = []\n",
    "        stage = game[0]\n",
    "        res = game[5]\n",
    "        #the result of the game will constitute our y set. 0 = home loss, 1 = home draw, 3 = home win.\n",
    "        y.append(resOneHot(res))\n",
    "        home = game[1]\n",
    "        away = game[2]\n",
    "        homeLoc = teamDic[home]\n",
    "        awayLoc = teamDic[away]\n",
    "        #a training example will be a 10 * 824, with the home teams most recent 5 games as the first 5 values\n",
    "        #followed by the away teams most recent 5 games.\n",
    "        for i in range((stage-6), (stage - 1)):\n",
    "            game = season.performances[homeLoc].performance[i]\n",
    "            #first two items in game are the stage and away team api Id which I don't use in this\n",
    "            # model\n",
    "            game1 = game[2:]\n",
    "            if len(game1) < 824:\n",
    "                for k in range(len(game1), 824):\n",
    "                    game1.append(0)\n",
    "            if len(game1) != 824:        \n",
    "                print(len(game1))\n",
    "            for d in game1:\n",
    "                example.append(d)\n",
    "        for j in range((stage-6), (stage - 1)):\n",
    "            game = season.performances[awayLoc].performance[i]\n",
    "            game1 = game[2:]\n",
    "            if len(game1) < 824:\n",
    "                for k in range(len(game1), 824):\n",
    "                    game1.append(0)\n",
    "            if len(game1) != 824:        \n",
    "                print(len(game1))\n",
    "            for d in game1:\n",
    "                example.append(d)\n",
    "        x.append(example)\n",
    "    return x, y\n",
    "\n",
    "def generateSets(seasons):\n",
    "    trainX = []\n",
    "    trainY = []\n",
    "    testX = []\n",
    "    testY = []\n",
    "    for i in range(6):\n",
    "        season1 = seasons.seasonData[i].pVals[0]\n",
    "        numTeams = len(season1.teams)\n",
    "        n = int(numTeams / 2 *  5)\n",
    "        t = season1.info[n:]\n",
    "        x ,y = createDataSet2(t, season1)\n",
    "        trainX = trainX + x\n",
    "        trainY = trainY + y\n",
    "    for j in range(2):\n",
    "        season1 = seasons.seasonData[j + 6].pVals[0]\n",
    "        numTeams = len(season1.teams)\n",
    "        t = season1.info[n:]\n",
    "        x ,y = createDataSet2(t, season1)\n",
    "        testX = testX + x\n",
    "        testY = testY + y\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "def filterX(tx):\n",
    "    xRet = []\n",
    "    for x in tx:\n",
    "        xTemp = []\n",
    "        for i in x:\n",
    "            if type(i) != type(1) and type(i) != type(1.):\n",
    "                xTemp.append(0)\n",
    "            else:\n",
    "                xTemp.append(i)\n",
    "        xRet.append(xTemp)\n",
    "    return xRet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7506 2502\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('soccerPerformancePrem.pickle', 'rb') as handle:\n",
    "    prem = pickle.load(handle)\n",
    "with open('soccerPerformanceLL.pickle', 'rb') as handle:\n",
    "    ll = pickle.load(handle)\n",
    "with open('soccerPerformanceGB.pickle', 'rb') as handle:\n",
    "    gb = pickle.load(handle)\n",
    "with open('soccerPerformanceFL.pickle', 'rb') as handle:\n",
    "    fl = pickle.load(handle)\n",
    "trainX1, trainY1, testX1, testY1 = generateSets(prem)\n",
    "trainX2, trainY2, testX2, testY2 = generateSets(ll)\n",
    "trainX3, trainY3, testX3, testY3 = generateSets(gb)\n",
    "trainX4, trainY4, testX4, testY4 = generateSets(fl)\n",
    "\n",
    "trainX = trainX1 + trainX2 + trainX3 + trainX4\n",
    "trainY = trainY1 + trainY2 + trainY3 + trainY4\n",
    "testX = testX1 + testX2 + testX3 + testX4\n",
    "testY = testY1 + testY2 + testY3 + testY4\n",
    "trainX = filterX(trainX)\n",
    "testX = filterX(testX)\n",
    "\n",
    "\n",
    "\n",
    "print(len(trainY), len(testY))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-42-78044c51dd5d>:96 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step 0, training accuracy 0.5\n",
      "step 100, training accuracy 0.48\n",
      "step 200, training accuracy 0.42\n",
      "step 300, training accuracy 0.25\n",
      "step 400, training accuracy 0.19\n",
      "step 500, training accuracy 0.23\n",
      "step 600, training accuracy 0.23\n",
      "step 700, training accuracy 0.33\n",
      "step 800, training accuracy 0.16\n",
      "step 900, training accuracy 0.27\n",
      "accuracy is 0.247802\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import random as rand\n",
    "POOL = 4\n",
    "W1 = 32\n",
    "W2 = 16\n",
    "W3 = 8\n",
    "WF1 = 256\n",
    "NUMFEATURES = 3\n",
    "D1 = 32 #depths\n",
    "D2 = 64\n",
    "D3 = 128\n",
    "\n",
    "\n",
    "def cw(nLayers, p, w= 824):\n",
    "    ''' calculates the width for fully connected layer\n",
    "    args are number of layers,\n",
    "    pool size, and the width of the argument default to 824'''\n",
    "    w1 = float(w)\n",
    "    for i in range(nLayers):\n",
    "        w1 = math.ceil(w1/p)\n",
    "    return w1\n",
    "W_FINAL = cw(3, POOL)\n",
    "\n",
    "def genBatch(x, y, n =100, shuffle = True):\n",
    "    x1 = []\n",
    "    y1 = []\n",
    "    a = []\n",
    "    for j in range(len(y)):\n",
    "        a.append(j)\n",
    "    if shuffle:\n",
    "        rand.shuffle(a)\n",
    "    for i in range(n):\n",
    "        j = a[i]\n",
    "        x1.append(x[j])\n",
    "        y1.append(y[j])\n",
    "    return x1, y1\n",
    "    \n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 4, 2, 1],\n",
    "                        strides=[1, 4, 2, 1], padding='SAME')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 8240])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "\n",
    "W_conv1 = weight_variable([W1, 10, 1, D1])\n",
    "b_conv1 = bias_variable([D1])\n",
    "x_image = tf.reshape(x, [-1,824,10,1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([W2, 4, D1, D2])\n",
    "b_conv2 = bias_variable([D2])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "W_conv3 = weight_variable([W3, 2, D2, D3])\n",
    "b_conv3 = bias_variable([D3])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "W_fc1 = weight_variable([W_FINAL * 2 * D3, WF1])\n",
    "b_fc1 = bias_variable([WF1])\n",
    "h_pool3_flat = tf.reshape(h_pool3, [-1,W_FINAL * 2 * D3])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([256, 3])\n",
    "b_fc2 = bias_variable([3])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(1000):\n",
    "    x_batch, y_batch = genBatch(trainX, trainY) \n",
    "  \n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x:x_batch, y_: y_batch, keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: x_batch, y_:y_batch, keep_prob: 0.5})\n",
    "acc = 0\n",
    "for i in range(18):\n",
    "    x_btest = testX[i * 139: (i+1) * 139]\n",
    "    y_btest = testY[i * 139: (i+1) * 139]\n",
    "    temp = accuracy.eval(feed_dict={x: x_btest, y_: y_btest, keep_prob: 1.0})\n",
    "    acc += temp / 18.0\n",
    "print('accuracy is %g'%acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46083133493205436 0.2478017585931255 0.29136690647482016\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s = 0\n",
    "s1 = 0\n",
    "s2 = 0\n",
    "for i in range(len(testY)):\n",
    "    if testY[i][0] == 1:\n",
    "        s+= 1\n",
    "    elif testY[i][1] == 1:\n",
    "        s1 += 1\n",
    "    else:\n",
    "        s2 += 1\n",
    "print(s/2502, s1/2502, s2/2502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.501598721023\n"
     ]
    }
   ],
   "source": [
    "#first model that is better than a naive guess woot 46% is naive!!!\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "trainY2 = resVal(trainY)\n",
    "testY2 = resVal(testY)\n",
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "clf.fit(trainX, trainY2)\n",
    "print(clf.score(trainX, trainY2))\n",
    "print(clf.score(testX, testY2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "7506/7506 [==============================] - 6s - loss: 1.1744     \n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "7506/7506 [==============================] - 3s - loss: 1.0798     \n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "7506/7506 [==============================] - 3s - loss: 1.0695     \n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "7506/7506 [==============================] - 3s - loss: 1.0679     \n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/1\n",
      "7506/7506 [==============================] - 3s - loss: 1.0657     \n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/1\n",
      "7506/7506 [==============================] - 3s - loss: 1.0639     \n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/1\n",
      "7506/7506 [==============================] - 3s - loss: 1.0637     \n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/1\n",
      "7506/7506 [==============================] - 3s - loss: 1.0631     \n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/1\n",
      "7506/7506 [==============================] - 3s - loss: 1.0626     \n",
      "2502\n"
     ]
    }
   ],
   "source": [
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(5, 1648)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "trainX1 = timeStepX(trainX)\n",
    "testX1 = timeStepX(testX)\n",
    "\n",
    "for iteration in range(1, 10):\n",
    "    print\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(trainX1, trainY, batch_size=139, nb_epoch=1)\n",
    "score = model.evaluate(testX1, testY, verbose=0)\n",
    "yVals = model.predict_on_batch(testX1)\n",
    "print(len(yVals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46083133493205436\n"
     ]
    }
   ],
   "source": [
    "s4 = 0\n",
    "\n",
    "    \n",
    "\n",
    "for i in range(len(yVals)):\n",
    "    y = yVals[i]\n",
    "    y = list(y)\n",
    "    idx = y.index(max(y))\n",
    "    if testY[i][idx] == 1:\n",
    "        s4 += 1\n",
    "print(s4/2502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.47235644  0.26459688  0.26304665]\n",
      " [ 0.47235644  0.26459688  0.26304665]\n",
      " [ 0.47235644  0.26459688  0.26304665]\n",
      " [ 0.47235644  0.26459688  0.26304665]\n",
      " [ 0.47235644  0.26459688  0.26304665]\n",
      " [ 0.47235644  0.26459688  0.26304665]\n",
      " [ 0.47235644  0.26459688  0.26304665]\n",
      " [ 0.47235644  0.26459688  0.26304665]\n",
      " [ 0.47235644  0.26459688  0.26304665]\n",
      " [ 0.47235644  0.26459688  0.26304665]]\n"
     ]
    }
   ],
   "source": [
    "print(yVals[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
